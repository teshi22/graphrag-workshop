{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d562e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import graphrag.api as api\n",
    "from graphrag.config.load_config import load_config\n",
    "from graphrag.index.typing.pipeline_run_result import PipelineRunResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9c129",
   "metadata": {},
   "source": [
    "### handson ディレクトリ概要\n",
    "- `.env`: Graphrag 実行時の環境変数を配置する。\n",
    "- `settings.yaml`: Graphrag の設定ファイル。本演習のパラメータが定義されている。\n",
    "- `input/`: インデックス化対象となる元ドキュメントを格納する。\n",
    "- `output/`: build_index 実行後に作成されるエンティティやリレーションなどの成果物が保存される。\n",
    "- `cache/`・`logs/`: 実行時のキャッシュやログを保持し、再実行時の高速化やトラブルシュートに使う。\n",
    "- `prompts/`: 追加でカスタムプロンプトを定義したい場合に配置する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2a99b",
   "metadata": {},
   "source": [
    "このセルでは `handson` ディレクトリにある `settings.yaml` から設定を読み込み、`graphrag.api.build_index` を実行してインデックスを構築します。各ワークフローの成功／失敗が標準出力に表示されるため、実行後にログを確認して次の処理（データの可視化や検索）へ進みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb57712",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIRECTORY = \"./handson\"\n",
    "graphrag_config = load_config(Path(PROJECT_DIRECTORY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_result: list[PipelineRunResult] = await api.build_index(config=graphrag_config)\n",
    "\n",
    "for workflow_result in index_result:\n",
    "    status = f\"error\\n{workflow_result.errors}\" if workflow_result.errors else \"success\"\n",
    "    print(f\"Workflow Name: {workflow_result.workflow}\\tStatus: {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fccf218",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df = pd.read_parquet(f\"{PROJECT_DIRECTORY}/output/entities.parquet\")\n",
    "communities_df = pd.read_parquet(f\"{PROJECT_DIRECTORY}/output/communities.parquet\")\n",
    "community_reports_df = pd.read_parquet(\n",
    "    f\"{PROJECT_DIRECTORY}/output/community_reports.parquet\"\n",
    ")\n",
    "relationships_df = pd.read_parquet(f\"{PROJECT_DIRECTORY}/output/relationships.parquet\")\n",
    "documents_df = pd.read_parquet(f\"{PROJECT_DIRECTORY}/output/documents.parquet\")\n",
    "text_units_df = pd.read_parquet(f\"{PROJECT_DIRECTORY}/output/text_units.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fda8439",
   "metadata": {},
   "source": [
    "#### Entity カラム概要\n",
    "- `id`: 解析パイプライン内でユニークなエンティティ ID（UUID）。\n",
    "- `human_readable_id`: 連番の簡易 ID。グラフ表示やデバッグに便利。\n",
    "- `title`: エンティティ名。後続の可視化やクエリでノードラベルとして利用。\n",
    "- `type`: LLM が推定したカテゴリ（PERSON/ORGANIZATION など）。\n",
    "- `description`: エンティティの説明文。検索応答の根拠として活用。\n",
    "- `text_unit_ids`: このエンティティが登場するテキストユニット ID のリスト。\n",
    "- `frequency`: エンティティが参照された回数。重要度の簡易スコアとして使える。\n",
    "- `degree`: グラフ上で接続している関係数。ハブノードの特定に有用。\n",
    "- `x`, `y`: レイアウト計算済みの座標。ノートブック内でグラフを描画する際に使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e964fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0115a",
   "metadata": {},
   "source": [
    "#### Relationships カラム概要\n",
    "- `id`: 関係エッジのユニーク ID（UUID）。\n",
    "- `human_readable_id`: 連番で付与された簡易 ID。\n",
    "- `source` / `target`: エッジが結ぶエンティティのタイトル。`entities_df['title']` と対応。\n",
    "- `description`: LLM が生成した関係の説明文。\n",
    "- `weight`: 関係の重要度スコア。GraphWidget の線幅などに利用。\n",
    "- `combined_degree`: 接続するノード双方の次数から計算された指標。ハブ間の関係を把握しやすい。\n",
    "- `text_unit_ids`: 関係が出現したテキストユニット ID の一覧。根拠ドキュメント追跡に使える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d62ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "relationships_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8db255c",
   "metadata": {},
   "source": [
    "### Community Reports カラム概要\n",
    "- `id`: コミュニティレポートのユニーク ID（UUID）。\n",
    "- `human_readable_id`: 連番で付いた簡易 ID。\n",
    "- `community`: レポート対象コミュニティの ID。`communities_df['id']` と対応。\n",
    "- `level`: コミュニティの階層レベル。0（グローバル）～ N。\n",
    "- `parent` / `children`: 階層構造を表す親コミュニティ ID と子コミュニティ ID のリスト。\n",
    "- `title`: レポートの見出しとして使われる要約タイトル。\n",
    "- `summary`: コミュニティ全体の要約文。\n",
    "- `full_content`: 箇条書きやセクションを含む詳細レポート本文。\n",
    "- `full_content_json`: `full_content` を JSON 構造化したバージョン。後続の加工や UI 連携で利用。\n",
    "- `findings`: 主要な洞察・リスク・推奨事項を配列で保持。\n",
    "- `rank`: コミュニティの重要度スコア。\n",
    "- `rating_explanation`: ランク付けに関する説明文。\n",
    "- `period`: 解析対象期間など、レポートに紐づく時間情報（存在すれば）。\n",
    "- `size`: コミュニティに属するテキストユニット数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7aa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "community_reports_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc8067",
   "metadata": {},
   "source": [
    "## Local Search の仕組み\n",
    "\n",
    "1. **ユーザーのクエリ**（＋過去の会話履歴）が入力される。  \n",
    "2. クエリ内容に基づき、**知識グラフから意味的に関連する可能性のあるエンティティ**を抽出する（embedding 類似度などを利用）。  \n",
    "3. 抽出したエンティティを起点に、以下の候補情報を収集する：  \n",
    "   - 元ドキュメントのテキストチャンク（Entity-Text Units）  \n",
    "   - 関関連エンティティや関係性（Entity-Entity / Relationships）  \n",
    "   - エンティティ属性・メタデータ（Covariates）  \n",
    "   - コミュニティ構造・レポート（Community Reports）  \n",
    "4. 収集したチャンク・エンティティ・関係・レポートを**ランキングとフィルタリング**で精査し、使用する情報のみを選定する。  \n",
    "5. 選ばれた情報（テキスト + 構造化データ）を **LLM に入力し、最終的な回答を生成**する。\n",
    "\n",
    "> Local Search は、全文検索だけでなく **知識グラフの構造化情報とテキスト情報を組み合わせるハイブリッド手法**で、高精度なエンティティ中心検索を実現します。\n",
    "\n",
    "参考：https://microsoft.github.io/graphrag/query/local_search/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19a7b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, context = await api.local_search(\n",
    "    config=graphrag_config,\n",
    "    entities=entities_df,\n",
    "    communities=communities_df,\n",
    "    community_reports=community_reports_df,\n",
    "    text_units=text_units_df,\n",
    "    relationships=relationships_df,\n",
    "    covariates=None,\n",
    "    community_level=2,\n",
    "    response_type=\"Multiple Paragraphs\",\n",
    "    query=\"Azure OpenAIで使えるモデルを教えて\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4da562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b9387",
   "metadata": {},
   "source": [
    "## Global Search の仕組み\n",
    "\n",
    "1. ドキュメント群からナレッジグラフを構築し、グラフ内のエンティティが属する **コミュニティ (Community)** を検出／クラスタリングする。  \n",
    "2. 各コミュニティに対して、LLM による要約を作成し **Community Report（コミュニティ要約）** を生成する。  \n",
    "3. ユーザーのクエリに対し、指定レベルのコミュニティ階層に属するすべての Community Report を対象に、Map-Reduce 方式で応答生成を試みる。  \n",
    "   - Map工程：Community Report を一定サイズのテキストチャンクに分割 → 各チャンクごとに中間応答 (Intermediate Response) を生成  \n",
    "   - Reduce工程：すべての中間応答をフィルタ／統合 → 最終的な応答を生成  \n",
    "4. 必要に応じて、コミュニティ階層のレベル (抽象度) を調整 — 抽象度の低いレポートは情報量が多く、詳細な応答が可能だが、コストやトークン消費が増える。  \n",
    "5. この手法により、ドキュメント全体を俯瞰した **広範なテーマ、全体構造、総合的傾向** への問いに対して、一貫性のある総合的な回答を返すことが可能となる。  \n",
    "\n",
    "参考：https://microsoft.github.io/graphrag/query/global_search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3dd2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, context = await api.global_search(\n",
    "    config=graphrag_config,\n",
    "    entities=entities_df,\n",
    "    communities=communities_df,\n",
    "    community_reports=community_reports_df,\n",
    "    community_level=2,\n",
    "    dynamic_community_selection=False,\n",
    "    response_type=\"Multiple Paragraphs\",\n",
    "    query=\"Azure OpenAIで使えるモデルを教えて\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff8e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557b7c4",
   "metadata": {},
   "source": [
    "## DRIFT Search の仕組み\n",
    "\n",
    "1. ユーザーのクエリが入力されると、まず **“コミュニティ要約 (Community Report)”** の集合の中から、クエリと意味的に最も関連性の高い上位 K 件を選び出し、**初期回答＋フォローアップ質問** を生成する。  \n",
    "2. 生成されたフォローアップ質問に対しては、**Local Search の仕組み**を使って、より詳細な情報の探索と中間回答の収集を行う。  \n",
    "3. フォローアップ→Local Search→さらに質問生成、というサイクルを、あらかじめ定められた条件 (繰り返し回数やスコア閾値) に基づいて繰り返すことで、情報の深掘りと精度向上を図る。  \n",
    "4. 最終的に、Global 的視点（コミュニティ要約ベース）と Local 的視点（テキストチャンク＋エンティティ構造ベース）が統合された、**階層構造つきの質問／回答群** を生成する。  \n",
    "5. このアプローチにより、広範囲な知識の「俯瞰 (global)」と、個別情報の「精査 (local)」を両立させ、**多様かつ文脈に即した回答** を得ることが可能になる。  \n",
    "\n",
    "参考：https://microsoft.github.io/graphrag/query/drift_search/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d81f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, context = await api.drift_search(\n",
    "    config=graphrag_config,\n",
    "    entities=entities_df,\n",
    "    communities=communities_df,\n",
    "    community_reports=community_reports_df,\n",
    "    text_units=text_units_df,\n",
    "    relationships=relationships_df,\n",
    "    community_level=2,\n",
    "    response_type=\"Multiple Paragraphs\",\n",
    "    query=\"Azure OpenAIで使えるモデルを教えて\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
